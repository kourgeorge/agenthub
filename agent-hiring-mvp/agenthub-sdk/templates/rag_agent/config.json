{
  "name": "RAG Agent",
  "description": "A RAG (Retrieval-Augmented Generation) agent that takes a document source and multiple questions to provide accurate answers based on document content.",
  "version": "1.0.0",
  "author": "AgentHub Team",
  "email": "team@agenthub.com",
  "entry_point": "agent.py",
  "agent_type": "function",
  "category": "research",
  "pricing_model": "per_use",
  "price_per_use": 1.6,
  "max_execution_time": 300,
  "memory_limit": "1GB",
  "tags": [
    "rag",
    "document-qa",
    "knowledge-base",
    "openai",
    "llamaindex"
  ],
  "requirements": [
    "llama-index",
    "llama-index-readers-web",
    "llama-index-readers-file",
    "llama-index-llms-openai",
    "llama-index-embeddings-openai",
    "python-dotenv",
    "requests",
    "beautifulsoup4",
    "pypdf"
  ],
  "config_schema": {
    "functions": [
      {
        "name": "execute",
        "description": "Process RAG queries against a document source",
        "inputSchema": {
          "type": "object",
          "properties": {
            "document_source": {
              "type": "string",
              "description": "URL or path to the document to analyze (optional if pasting content in questions field)"
            },
            "questions": {
              "type": "string",
              "description": "Questions to ask about the document content (one per line), OR paste document content directly here if no document_source is provided"
            },
            "model_name": {
              "type": "string",
              "description": "OpenAI model to use for LLM",
              "enum": ["gpt-3.5-turbo", "gpt-4", "gpt-4o"],
              "default": "gpt-3.5-turbo"
            },
            "embedding_model": {
              "type": "string",
              "description": "OpenAI model to use for embeddings",
              "enum": ["text-embedding-ada-002", "text-embedding-3-small", "text-embedding-3-large"],
              "default": "text-embedding-ada-002"
            },
            "temperature": {
              "type": "number",
              "description": "Temperature for LLM responses",
              "default": 0
            },
            "chunk_size": {
              "type": "string",
              "description": "Size of text chunks for processing",
              "enum": ["512", "1024", "2048"],
              "default": "1024"
            },
            "chunk_overlap": {
              "type": "integer",
              "description": "Overlap between text chunks",
              "default": 200
            },
            "max_tokens": {
              "type": "integer",
              "description": "Maximum tokens for response",
              "default": 1000
            }
          },
          "required": ["questions"],
          "additionalProperties": false
        },
        "outputSchema": {
          "type": "object",
          "properties": {
            "answers": {
              "type": "array",
              "description": "List of answers to the questions",
              "items": {
                "type": "object",
                "properties": {
                  "question": {"type": "string"},
                  "answer": {"type": "string"},
                  "confidence": {"type": "number"},
                  "sources": {"type": "array", "items": {"type": "string"}}
                }
              }
            },
            "document_source": {
              "type": "string",
              "description": "The document source that was analyzed"
            },
            "questions": {
              "type": "array",
              "description": "List of questions that were asked",
              "items": {"type": "string"}
            },
            "total_questions": {
              "type": "integer",
              "description": "Total number of questions processed"
            },
            "model_used": {
              "type": "string",
              "description": "LLM model that was used for processing"
            },
            "embedding_model": {
              "type": "string",
              "description": "Embedding model that was used"
            },
            "chunk_size": {
              "type": "string",
              "description": "Chunk size used for processing"
            },
            "chunk_overlap": {
              "type": "integer",
              "description": "Chunk overlap used for processing"
            }
          },
          "required": ["answers", "document_source", "questions", "total_questions"],
          "additionalProperties": false
        }
      }
    ]
  }
} 